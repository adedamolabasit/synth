Synth Backend API Documentation
ðŸ“Œ Overview

The Synth backend handles:

File uploads (audio + video)

Metadata extraction

Whisper-based lyric generation

IPFS upload

Video and audio record management

Story Protocol asset registration

Public REST API with Swagger UI

It is built in Express + TypeScript and organized into a clean service + controller architecture.

ðŸ§­ Architecture
/controllers

Handle request/response logic.

audioController.ts

videoController.ts

/services

Encapsulate logic for:

Audio metadata extraction

Whisper transcription

IPFS uploads

Video record processing

Story Protocol communications

/utils

compress.ts â€“ gzip compression

pinata.ts â€“ IPFS upload helpers

logger.ts â€“ API logging

envValidator.ts â€“ environment validation

/middleware

upload.ts â€“ Multer audio/video upload handler

/model

Mongoose schemas:

audioEntry

videoEntry

userEntry

ðŸŽµ Audio API
POST /api/audio/upload

Upload audio â†’ extract metadata â†’ transcribe â†’ store in DB.

GET /api/audio/:walletAddress

Get all audio entries for a wallet.

GET /api/audio/details/:id

Retrieve a single audio entry.

ðŸŽ¥ Video API
POST /api/video/upload

Upload the recorded video file (from canvas).

PUT /api/video/register-ip

Update video with Story Protocol IP asset info.

PUT /api/video/publish

Publish video + metadata via Pinata/IPFS.

DELETE /api/video/:id

Delete a user's video.

ðŸ§ª Swagger Docs

The backend generates swagger docs using:

/swagger


Open your browser:

http://localhost:3000/api/docs

ðŸ”— Dependencies

OpenAI Whisper (lyrics)

music-metadata (audio analysis)

Pinata (IPFS)

Mongoose (MongoDB)

Story Protocol (IP registration)